# file: examples/agent_integration_demo.py
"""
AI Agent Integration Demo
==========================
æ¼”ç¤ºAI Agentå¦‚ä½•ä½¿ç”¨å·¥å…·ä¸DAWäº¤äº’

åœºæ™¯ï¼š
1. Agentä½¿ç”¨OpenAI Function Callingæ ¼å¼çš„å·¥å…·
2. Agentå¯ä»¥åˆ›å»ºéŸ³ä¹é¡¹ç›®
3. Agentå¯ä»¥æ·»åŠ è½¨é“å’Œæ’ä»¶
4. Agentå¯ä»¥åˆ›å»ºMIDIå†…å®¹
5. Agentå¯ä»¥æŸ¥è¯¢é¡¹ç›®çŠ¶æ€
6. æ”¯æŒæ‰€æœ‰ä¸‰ç§å¼•æ“ï¼ˆMock/Real/DawDreamerï¼‰
"""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from MuzaiCore.drivers.mock.manager import MockDAWManager
from MuzaiCore.drivers.real.manager import RealDAWManager
from MuzaiCore.drivers.dawdreamer_driver.manager import DawDreamerDAWManager
from MuzaiCore.facade import DAWFacade
from MuzaiCore.services import *
from MuzaiCore.agent.tools import AgentToolkit


def print_banner():
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘         ğŸ¤–  AI Agent + MuzaiCore Integration  ğŸ¤–            â•‘
    â•‘                                                              â•‘
    â•‘           Demonstrate Agent-Driven Music Creation            â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def print_section(title: str):
    print(f"\n{'='*70}")
    print(f"  {title}")
    print('=' * 70)


def create_daw_system(engine_type: str = "mock"):
    """
    åˆ›å»ºDAWç³»ç»Ÿ
    
    Args:
        engine_type: "mock", "real", "dawdreamer"
    """
    print(f"\n[System] Initializing {engine_type.upper()} engine...")

    if engine_type == "mock":
        manager = MockDAWManager()
    elif engine_type == "real":
        manager = RealDAWManager(sample_rate=48000, block_size=512)
    elif engine_type == "dawdreamer":
        manager = DawDreamerDAWManager(sample_rate=48000, block_size=512)
    else:
        raise ValueError(f"Unknown engine type: {engine_type}")

    # åˆ›å»ºServices
    services = {
        "project": ProjectService(manager),
        "transport": TransportService(manager),
        "nodes": NodeService(manager, manager.plugin_registry),  # ä½¿ç”¨V2
        "routing": RoutingService(manager),
        "editing": EditingService(manager),
        "history": HistoryService(manager),
        "query": QueryService(manager, manager.plugin_registry),
        "system": SystemService(manager, manager.plugin_registry)
    }

    daw = DAWFacade(manager, services)

    print(f"âœ“ {engine_type.upper()} engine initialized")

    return daw, manager


def demo_tool_discovery(toolkit: AgentToolkit):
    """æ¼”ç¤ºå·¥å…·å‘ç°"""
    print_section("PART 1: Tool Discovery")

    print("\n[1.1] Available tool categories:")
    from MuzaiCore.agent.tools import ToolCategory

    for category in ToolCategory:
        tools = toolkit.list_tools(category)
        print(f"  - {category.value}: {len(tools)} tools")

    print("\n[1.2] Sample tools (OpenAI format):")
    openai_tools = toolkit.get_tools_for_openai()

    for tool in openai_tools[:5]:
        print(f"\n  Tool: {tool['name']}")
        print(f"  Description: {tool['description']}")
        print(f"  Parameters: {len(tool['parameters']['properties'])} params")


def demo_agent_workflow(toolkit: AgentToolkit):
    """æ¼”ç¤ºAgentå·¥ä½œæµ"""
    print_section("PART 2: Agent Workflow Simulation")

    print("\n[Simulating AI Agent creating a music project]")
    print("-" * 70)

    # æ­¥éª¤1ï¼šåˆ›å»ºé¡¹ç›®
    print("\n[Agent] I need to create a new project first...")
    result = toolkit.execute_tool("create_project", name="AI Generated Song")
    print(f"[System] {result.message}")

    if result.status != "success":
        print("[Agent] Failed to create project. Stopping.")
        return

    project_id = result.data['project_id']
    print(f"[Agent] Great! Got project_id: {project_id[:16]}...")

    # æ­¥éª¤2ï¼šè®¾ç½®é¡¹ç›®å‚æ•°
    print("\n[Agent] Let me set the tempo to 128 BPM...")
    result = toolkit.execute_tool("set_tempo",
                                  project_id=project_id,
                                  bpm=128.0)
    print(f"[System] {result.message}")

    # æ­¥éª¤3ï¼šåˆ›å»ºè½¨é“
    print("\n[Agent] Now I'll create an instrument track for the melody...")
    result = toolkit.execute_tool("create_instrument_track",
                                  project_id=project_id,
                                  name="Lead Synth")
    print(f"[System] {result.message}")

    if result.status != "success":
        print("[Agent] Failed to create track. Continuing anyway...")
        lead_track_id = None
    else:
        lead_track_id = result.data['node_id']
        print(f"[Agent] Track created with ID: {lead_track_id[:16]}...")

    # æ­¥éª¤4ï¼šæ·»åŠ æ’ä»¶
    if lead_track_id:
        print("\n[Agent] Adding a synthesizer plugin to the track...")
        result = toolkit.execute_tool(
            "add_plugin",
            project_id=project_id,
            track_id=lead_track_id,
            plugin_id="muzaicore.builtin.basic_synth")
        print(f"[System] {result.message}")
        print(
            f"[Agent] Plugin added using {result.data.get('engine_type', 'unknown')} engine"
        )

    # æ­¥éª¤5ï¼šåˆ›å»ºMIDIå†…å®¹
    if lead_track_id:
        print("\n[Agent] Creating a MIDI clip for the melody...")
        result = toolkit.execute_tool("create_midi_clip",
                                      project_id=project_id,
                                      track_id=lead_track_id,
                                      start_beat=0.0,
                                      duration_beats=4.0,
                                      name="Melody Pattern")
        print(f"[System] {result.message}")

        if result.status == "success":
            clip_id = result.data['clip_id']
            print(f"[Agent] Clip created: {clip_id[:16]}...")

            # æ·»åŠ éŸ³ç¬¦
            print("\n[Agent] Adding notes to the clip...")
            notes = [
                {
                    "pitch": 60,
                    "velocity": 100,
                    "start_beat": 0.0,
                    "duration_beats": 0.5
                },
                {
                    "pitch": 64,
                    "velocity": 95,
                    "start_beat": 0.5,
                    "duration_beats": 0.5
                },
                {
                    "pitch": 67,
                    "velocity": 100,
                    "start_beat": 1.0,
                    "duration_beats": 0.5
                },
                {
                    "pitch": 72,
                    "velocity": 105,
                    "start_beat": 1.5,
                    "duration_beats": 1.5
                },
            ]

            result = toolkit.execute_tool("add_notes",
                                          project_id=project_id,
                                          clip_id=clip_id,
                                          notes=notes)
            print(f"[System] {result.message}")
            print(f"[Agent] Added {len(notes)} notes to the melody")

    # æ­¥éª¤6ï¼šæŸ¥è¯¢é¡¹ç›®çŠ¶æ€
    print("\n[Agent] Let me check the current project status...")
    result = toolkit.execute_tool("get_project_overview",
                                  project_id=project_id)

    if result.status == "success":
        print(f"[System] {result.message}")
        print(f"[Agent] Project overview:")
        print(f"  - Tempo: {result.data['tempo']} BPM")
        print(f"  - Tracks: {result.data['node_count']}")
        print(
            f"  - Time Signature: {result.data['time_signature'][0]}/{result.data['time_signature'][1]}"
        )

    # æ­¥éª¤7ï¼šåˆ—å‡ºæ‰€æœ‰èŠ‚ç‚¹
    print("\n[Agent] Listing all tracks in the project...")
    result = toolkit.execute_tool("list_nodes", project_id=project_id)

    if result.status == "success":
        print(f"[System] Found {result.data['count']} nodes:")
        for node in result.data['nodes']:
            print(f"  - {node['name']} ({node['type']})")

    # æ­¥éª¤8ï¼šä¿å­˜é¡¹ç›®
    print("\n[Agent] Finally, let me save the project...")
    result = toolkit.execute_tool("save_project",
                                  project_id=project_id,
                                  file_path="ai_generated_song.mzc")
    print(f"[System] {result.message}")

    print("\n[Agent] âœ“ Music project creation complete!")


def demo_tool_documentation(toolkit: AgentToolkit):
    """æ¼”ç¤ºå·¥å…·æ–‡æ¡£"""
    print_section("PART 3: Tool Documentation")

    print("\n[3.1] Documentation for 'create_midi_clip' tool:")
    print("-" * 70)

    doc = toolkit.get_tool_documentation("create_midi_clip")
    print(doc)

    print("\n[3.2] Documentation for 'add_notes' tool:")
    print("-" * 70)

    doc = toolkit.get_tool_documentation("add_notes")
    print(doc)


def demo_openai_integration(toolkit: AgentToolkit):
    """æ¼”ç¤ºOpenAIé›†æˆæ ¼å¼"""
    print_section("PART 4: OpenAI Function Calling Format")

    print("\n[4.1] Sample OpenAI function definition:")

    openai_tools = toolkit.get_tools_for_openai()

    # æ‰¾åˆ°create_projectå·¥å…·
    create_project_tool = next(
        (t for t in openai_tools if t['name'] == 'create_project'), None)

    if create_project_tool:
        print("\nTool definition (JSON):")
        print(json.dumps(create_project_tool, indent=2))

        print("\n[4.2] How to use with OpenAI API:")
        print("""
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "Create a music project called 'My Song'"}
    ],
    functions=toolkit.get_tools_for_openai(),
    function_call="auto"
)

# Extract function call
function_call = response.choices[0].message.function_call
tool_name = function_call.name
arguments = json.loads(function_call.arguments)

# Execute the tool
result = toolkit.execute_tool(tool_name, **arguments)
        """)


def demo_anthropic_integration(toolkit: AgentToolkit):
    """æ¼”ç¤ºAnthropicé›†æˆæ ¼å¼"""
    print_section("PART 5: Anthropic Tool Format")

    print("\n[5.1] Sample Anthropic tool definition:")

    anthropic_tools = toolkit.get_tools_for_anthropic()

    # æ‰¾åˆ°create_projectå·¥å…·
    create_project_tool = next(
        (t for t in anthropic_tools if t['name'] == 'create_project'), None)

    if create_project_tool:
        print("\nTool definition (JSON):")
        print(json.dumps(create_project_tool, indent=2))

        print("\n[5.2] How to use with Anthropic API:")
        print("""
import anthropic

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    tools=toolkit.get_tools_for_anthropic(),
    messages=[
        {"role": "user", "content": "Create a music project called 'My Song'"}
    ]
)

# Extract tool use
for content in response.content:
    if content.type == "tool_use":
        tool_name = content.name
        arguments = content.input
        
        # Execute the tool
        result = toolkit.execute_tool(tool_name, **arguments)
        """)


def demo_error_handling(toolkit: AgentToolkit):
    """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
    print_section("PART 6: Error Handling")

    print("\n[6.1] Testing invalid parameters:")

    # æ— æ•ˆçš„tempoå€¼
    print("\n[Test] Setting tempo to invalid value (-100)...")
    result = toolkit.execute_tool("set_tempo", project_id="test", bpm=-100.0)
    print(f"[Result] Status: {result.status}")
    print(f"[Result] Message: {result.message}")

    # ç¼ºå°‘å¿…éœ€å‚æ•°
    print("\n[Test] Creating project without name...")
    result = toolkit.execute_tool("create_project")
    print(f"[Result] Status: {result.status}")
    print(f"[Result] Message: {result.message}")

    # ä¸å­˜åœ¨çš„å·¥å…·
    print("\n[Test] Calling non-existent tool...")
    result = toolkit.execute_tool("non_existent_tool")
    print(f"[Result] Status: {result.status}")
    print(f"[Result] Message: {result.message}")


def print_summary():
    """æ‰“å°æ€»ç»“"""
    print_section("Demo Complete")

    summary = """
    ğŸ‰ AI Agent Integration Demo Complete!
    
    Demonstrated Features:
    
    âœ“ Tool Discovery
      - 40+ tools organized by category
      - OpenAI Function Calling format
      - Anthropic Tool format
      - Complete documentation
    
    âœ“ Agent Workflow
      - Project creation
      - Track and plugin management
      - MIDI content creation
      - Project state queries
      - Error handling
    
    âœ“ Multi-Engine Support
      - Mock engine (fast testing)
      - Real engine (Python DSP)
      - DawDreamer engine (VST3 support)
      - Automatic engine detection
      - Transparent plugin creation
    
    âœ“ LLM Integration
      - OpenAI GPT-4 compatible
      - Anthropic Claude compatible
      - Structured tool definitions
      - Parameter validation
      - Clear error messages
    
    Architecture Benefits:
    
    â€¢ Unified Interface
      - Single toolkit for all engines
      - Consistent tool format
      - Automatic adaptation
    
    â€¢ Type Safety
      - Parameter validation
      - Type checking
      - Range verification
    
    â€¢ Discoverability
      - Self-documenting tools
      - Rich descriptions
      - Usage examples
    
    â€¢ Extensibility
      - Easy to add new tools
      - Pluggable architecture
      - Engine-agnostic design
    
    Next Steps:
    
    1. Integrate with real LLM (GPT-4/Claude)
    2. Add more complex workflows
    3. Implement multi-turn conversations
    4. Add tool chaining capabilities
    5. Create domain-specific agents
    """

    print(summary)
    print("  " + "â•" * 66)
    print("  ğŸ¤– AI-Powered Music Production Ready! ğŸ¤–")
    print("  " + "â•" * 66 + "\n")


def main():
    """ä¸»ç¨‹åº"""
    try:
        print_banner()

        # é€‰æ‹©å¼•æ“ç±»å‹
        print("\nSelect engine type:")
        print("  1. Mock (fastest, for testing)")
        print("  2. Real (Python DSP, real audio)")
        print("  3. DawDreamer (VST3 support, best quality)")

        choice = input("\nEnter choice (1-3, default=1): ").strip() or "1"

        engine_map = {"1": "mock", "2": "real", "3": "dawdreamer"}

        engine_type = engine_map.get(choice, "mock")

        # åˆ›å»ºDAWç³»ç»Ÿ
        print_section("Initialization")
        daw, manager = create_daw_system(engine_type)

        # åˆ›å»ºAgentå·¥å…·åŒ…
        toolkit = AgentToolkit(daw)
        print(
            f"âœ“ Agent toolkit initialized with {len(toolkit.list_tools())} tools"
        )

        # è¿è¡Œæ¼”ç¤º
        demo_tool_discovery(toolkit)
        demo_agent_workflow(toolkit)
        demo_tool_documentation(toolkit)
        demo_openai_integration(toolkit)
        demo_anthropic_integration(toolkit)
        demo_error_handling(toolkit)

        print_summary()

        return 0

    except KeyboardInterrupt:
        print("\n\nâš ï¸  Demo interrupted by user")
        return 1

    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
